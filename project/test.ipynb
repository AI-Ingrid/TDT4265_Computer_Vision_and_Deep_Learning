{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torchvision.ops as ops\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.zeros(1,3,128,1024)\n",
    "\n",
    "def forward_first_layer(model, image):\n",
    "        \"\"\"Executing forward pass for the zeroth Retina Net layer\"\"\"\n",
    "        x = model.conv1(image)\n",
    "        x = model.bn1(x)\n",
    "        x = model.relu(x)\n",
    "        x = model.maxpool(x)\n",
    "        return x\n",
    "\n",
    "class Layer(nn.Sequential):\n",
    "    def __init__(self,channels,layer_index):\n",
    "        # [1, 512, 4, 32]\n",
    "        super().__init__(\n",
    "            nn.ReLU(),\n",
    "            #[64, 128, 256, 512, 64, 64],\n",
    "            #i= 512, o=64\n",
    "            #i=64, o=64\n",
    "            # next\n",
    "            # i=64, o=64\n",
    "            # i=64, o=64\n",
    "            nn.Conv2d(in_channels=channels[layer_index-1], out_channels=channels[layer_index], kernel_size=1, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=channels[layer_index], out_channels=channels[layer_index], kernel_size=1, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0:  torch.Size([1, 64, 32, 256])\n",
      "feat0:  torch.Size([1, 64, 32, 256])\n",
      "feat1:  torch.Size([1, 128, 16, 128])\n",
      "feat2:  torch.Size([1, 256, 8, 64])\n",
      "feat3:  torch.Size([1, 512, 4, 32])\n",
      "feat4:  torch.Size([1, 512, 2, 16])\n",
      "feat5:  torch.Size([1, 512, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "#out_channels = [64, 128, 256, 512, 64, 64] # without fpn\n",
    "out_channels = [256, 256, 256, 256, 512 , 256]\n",
    "out_channels = [512 , 512, 512, 512, 512, 512]\n",
    "feature_sizes=[[32, 256], [16, 128], [8, 64], [4, 32], [2, 16], [1, 8]],\n",
    "\n",
    "model = models.resnet34(pretrained=True)\n",
    "layer5 = Layer(out_channels, 4)\n",
    "layer6 = Layer(out_channels, 5)\n",
    "\n",
    "fpn = ops.FeaturePyramidNetwork([64, 128, 256, 512, 512, 512], 512)\n",
    "oout_features = []\n",
    "features_dict = OrderedDict()\n",
    "\n",
    "# Layer 0\n",
    "x = forward_first_layer(model,img)\n",
    "print('layer 0: ', x.shape)\n",
    "\n",
    "# Layer 1\n",
    "features_dict['feat0'] = model.layer1(x)\n",
    "print('feat0: ', features_dict['feat0'].shape)\n",
    "\n",
    "# Layer 2\n",
    "features_dict['feat1'] = model.layer2(features_dict['feat0'])\n",
    "print('feat1: ', features_dict['feat1'].shape)\n",
    "\n",
    "# Layer 3\n",
    "features_dict['feat2'] = model.layer3(features_dict['feat1'])\n",
    "print('feat2: ', features_dict['feat2'].shape)\n",
    "\n",
    "# Layer 4\n",
    "features_dict['feat3'] = model.layer4(features_dict['feat2'])\n",
    "print('feat3: ', features_dict['feat3'].shape)\n",
    "\n",
    "#img3 = torch.zeros([1,512,4,32])\n",
    "# Layer 5\n",
    "features_dict['feat4'] = layer5(features_dict['feat3'])\n",
    "print('feat4: ', features_dict['feat4'].shape)\n",
    "\n",
    "# Layer 6\n",
    "features_dict['feat5'] = layer6(features_dict['feat4'])\n",
    "print('feat5: ', features_dict['feat5'].shape)\n",
    "# Forward to FPN\n",
    "out_features = fpn(features_dict)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
